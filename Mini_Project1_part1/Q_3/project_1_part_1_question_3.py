# -*- coding: utf-8 -*-
"""Project_1_Part_1_Question_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MPHV7xZUF6Ao51fLnl4uhhEPIYMNugaC

# Part 1
"""

!pip install --upgrade --no-cache-dir gdown
!gdown 14ko2e1olsQdldRdFtD9A26r6W3mVl7wP

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('/content/heart_disease_health_indicators.csv')
df

"""# Part 2"""

from sklearn.utils import shuffle

# Separate the data into two classes
class_0_data = df[df['HeartDiseaseorAttack'] == 0]
class_1_data = df[df['HeartDiseaseorAttack'] == 1]

# choosing 100 random datas
nclass_0_data = class_0_data.sample(n=100, random_state=93)
nclass_1_data = class_1_data.sample(n=100, random_state=93)

# Combine datas
new_df = pd.concat([nclass_0_data, nclass_1_data], ignore_index=True)
df = shuffle(new_df, random_state=93)
df

"""# Part 3"""

X = df.drop('HeartDiseaseorAttack', axis=1)
y = df['HeartDiseaseorAttack']
X.shape, y.shape

"""## Classification"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=93, stratify=y)

# Display the dimensions of the training and testing sets
print(f'Dimensions of the training features: {X_train.shape}')
print(f'Dimensions of the training target: {y_train.shape}')
print(f'Dimensions of the testing features: {X_test.shape}')
print(f'Dimensions of the testing target: {y_test.shape}')

"""### Logistic Regression"""

LogReg_classifier = LogisticRegression(C=1.0, penalty='l2', solver='newton-cholesky', max_iter=150, random_state=93)
LogReg_classifier.fit(X_train, y_train)
y_pred = LogReg_classifier.predict(X_test)
LogReg_train_accuracy = LogReg_classifier.score(X_train, y_train)
LogReg_test_accuracy = LogReg_classifier.score(X_test, y_test)

y_pred, y_test

"""### SGD Classifier"""

SGD_classifier = SGDClassifier(alpha=0.0001, loss='log_loss', max_iter=150, penalty='l2', random_state=93)
SGD_classifier.fit(X_train, y_train)
y_pred1 = SGD_classifier.predict(X_test)
SGD_train_accuracy = SGD_classifier.score(X_train, y_train)
SGD_test_accuracy = SGD_classifier.score(X_test, y_test)

y_pred1, y_test

"""### Perceptron"""

perceptron_classifier = Perceptron(alpha=0.0001, penalty='l2', max_iter=200, random_state=93)
perceptron_classifier.fit(X_train, y_train)
y_pred2 = perceptron_classifier.predict(X_test)
perceptron_train_accuracy = perceptron_classifier.score(X_train, y_train)
perceptron_test_accuracy = perceptron_classifier.score(X_test, y_test)

y_pred2, y_test

"""### Accuracies"""

print(f"Logistic Regression Train Accuracy: {LogReg_train_accuracy:.2f}")
print(f"Logistic Regression Test Accuracy: {LogReg_test_accuracy:.2f}")

print(f"SGD Classifier Train Accuracy: {SGD_train_accuracy:.2f}")
print(f"SGD Classifier Test Accuracy: {SGD_test_accuracy:.2f}")

print(f"Perceptron Train Accuracy: {perceptron_train_accuracy:.2f}")
print(f"Perceptron Test Accuracy: {perceptron_test_accuracy:.2f}")

"""# Part 4

## SGD Classifier
"""

from sklearn.metrics import log_loss
error_hist = []
epochs = 5000

for _ in range(epochs):

    SGD_classifier.partial_fit(X_train, y_train, [0, 1])
    loss = log_loss(y_train , SGD_classifier.predict_proba(X_train))
    error_hist.append(loss)

plt.figure(figsize=(8, 6))
plt.plot(error_hist)
plt.xlabel("Number of Epochs")
plt.ylabel("Error")
plt.title('Loss Function for SGD Classifier method')
plt.grid(alpha=0.5)

"""# Part 5

## Logistic Regression
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score

conf_matrix = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot()
plt.title('Confusion matrix for Logistic Regression method')
plt.show()

precision = precision_score(y_test, y_pred)
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])

print("Precision of Logistic Regression method:", precision)
print("Specificity of Logistic Regression method:", specificity)

"""## SGD Classifier"""

conf_matrix1 = confusion_matrix(y_test, y_pred1)
disp1 = ConfusionMatrixDisplay(confusion_matrix=conf_matrix1)
disp1.plot()
plt.title('Confusion matrix for SGD Classifier method')
plt.show()

precision1 = precision_score(y_test, y_pred1)
specificity1 = conf_matrix1[0, 0] / (conf_matrix1[0, 0] + conf_matrix1[0, 1])

print("Precision of SGD Classifier method:", precision1)
print("Specificity of SGD Classifier method:", specificity1)

"""## Perceptron"""

conf_matrix2 = confusion_matrix(y_test, y_pred2)
disp2 = ConfusionMatrixDisplay(confusion_matrix=conf_matrix2)
disp2.plot()
plt.title('Confusion matrix for Perceptron method')
plt.show()

precision2 = precision_score(y_test, y_pred2)
specificity2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])

print("Precision of Perceptron method:", precision2)
print("Specificity of Perceptron method:", specificity2)